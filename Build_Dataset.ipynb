{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting DDI2013 XML format to tsv\n",
    "( SpERT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import bioc\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ddi_bert(gold_directory, output):\n",
    "    fp = open(output, 'w')\n",
    "    writer = csv.writer(fp, delimiter='\\t', lineterminator='\\n')\n",
    "    writer.writerow(['index', 'sentence', 'entity-1', 'entity-1-type', 'entity-2', 'entity-2-type', 'label' ])\n",
    "    cnt = 0\n",
    "    count = 0\n",
    "    false_ = 0\n",
    "    for root, dirs, files in os.walk(gold_directory):\n",
    "        for name in files:\n",
    "            pathname = os.path.join(root, name)\n",
    "            ##parsing the xml docs:             \n",
    "            tree = etree.parse(pathname)\n",
    "            for stag in tree.xpath('/document/sentence'):\n",
    "                sentence = bioc.BioCSentence()\n",
    "                sentence.offset = 0\n",
    "                sentence.text = stag.get('text')\n",
    "\n",
    "                ##Extracting entities\n",
    "                entities = {}\n",
    "                for etag in stag.xpath('entity'):\n",
    "                    id = etag.get('id')\n",
    "                    m = re.match('(\\d+)-(\\d+)', etag.get('charOffset'))\n",
    "                    if m is None:\n",
    "                        logging.warning('{}:{}: charOffset does not match. {}'.format(\n",
    "                        output, id, etag.get('charOffset')))\n",
    "                        continue\n",
    "                    start = int(m.group(1))\n",
    "                    end = int(m.group(2)) + 1\n",
    "                    expected_text = etag.get('text')\n",
    "                    actual_text = sentence.text[start:end]\n",
    "                    if expected_text != actual_text:\n",
    "                        logging.warning('{}:{}: Text does not match. Expected {}. Actual {}'.format(\n",
    "                            output, id, repr(expected_text), repr(actual_text)))\n",
    "                    entities[id] = {\n",
    "                        'start': start,\n",
    "                        'end': end,\n",
    "                        'type': etag.get('type'),\n",
    "                        'id': id,\n",
    "                        'text': actual_text\n",
    "                    }\n",
    "                ##Extracting relations    \n",
    "                for rtag in stag.xpath('pair'):\n",
    "                    if rtag.get('ddi') == 'false':\n",
    "                        label = 'DDI-false'\n",
    "                        false_ += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        label = 'DDI-{}'.format(rtag.get('type'))\n",
    "                        cnt += 1\n",
    "                  \n",
    "                  \n",
    "                    e1 = entities.get(rtag.get('e1'))\n",
    "                    e2 = entities.get(rtag.get('e2'))\n",
    "                    \n",
    "                    text = sentence.text\n",
    "              \n",
    "                    row = {}\n",
    "                    row['sentence'] = text\n",
    "                    row['entity_1 '] = e1['text']\n",
    "                    row['entity_1_type'] = e1['type']\n",
    "                    row['entity_2 '] = e2['text']\n",
    "                    row['entity_2_type'] = e2['type']\n",
    "                    row['label'] = label\n",
    "                    count += 1\n",
    "                    writer.writerow([f'{rtag.get(\"id\")}',  row['sentence'], e1['text'], row['entity_1_type'], row['entity_2 '], row['entity_2_type'], row['label']])\n",
    "\n",
    "            \n",
    "   \n",
    "    print(f'Have {cnt} relations')\n",
    "    print(f'Have {false_} false instances')\n",
    "    print(f'Written {count} instances')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_directory = './original/Test'\n",
    "output = './test_added.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_ddi_bert(gold_directory, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting train and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/ddi2013-type/train_added.tsv',  sep='\\t')\n",
    "df_new = df\n",
    "\n",
    "df_new = df_new.sample(frac=1, random_state=42)\n",
    "split = int(0.8 * len(df_new))\n",
    "\n",
    "train_df = df_new[:split]\n",
    "valid_df = df_new[split:]\n",
    "\n",
    "train_df.to_csv('./train_train_added.tsv', sep='\\t')\n",
    "valid_df.to_csv('./train_dev_added.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting tsv to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "def tokenize_json(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [ str(t) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def create_entities(text, e1, e1_type, e2 , e2_type, index):  \n",
    "    \n",
    "    i = -1\n",
    "    e1_tok = tokenize_json(e1)\n",
    "    e2_tok = tokenize_json(e2)\n",
    "\n",
    "   \n",
    "  #######For handling the miscellaneous in train set \n",
    "    if e2 == 'InsP(3)':\n",
    "        e2 = 'InsP(3)-induced'\n",
    "    elif e1 == 'amphetamine':\n",
    "        e1 = 'ephedrine/amphetamine'\n",
    "    elif e2 == 'halothane':\n",
    "        e2 = 'enflurane;isoflurane;halothane;certain' \n",
    "    elif e2 == 'lithium':\n",
    "        e2 = 'polymyxins;lithium;magnesium'\n",
    "    elif e2 == 'procainamide':\n",
    "        e2 = 'salts;procainamide;and'   \n",
    "    elif e2 == 'gentamicin':\n",
    "        e2 = 'MDP)-gentamicin' \n",
    "    elif e2 == 'isoflurane':\n",
    "        e2 = 'enflurane;isoflurane;halothane;certain'\n",
    "    elif e2 == 'magnesium':\n",
    "        e2 = 'polymyxins;lithium;magnesium' \n",
    "         \n",
    "\n",
    "    doc = tokenize_json(text)\n",
    "  \n",
    "    ## Flags \n",
    "    match_1 = 0\n",
    "    match_2 = 0\n",
    "\n",
    "    #ENTITY 1\n",
    "    for t in doc:\n",
    "        i += 1\n",
    "        if t == e1 or t == e1_tok[0]:\n",
    "            if len(e1_tok) != 1:\n",
    "                print(f'Matched entity #1 is: {e1} ')\n",
    "                match_1 = 1\n",
    "                start_1 = i\n",
    "                end_1 = i + len(e1_tok)\n",
    "            else:\n",
    "                print(f'Matched entity #1 is: {e1} ')\n",
    "                match_1 = 1\n",
    "                start_1 = i\n",
    "                end_1 = i + 1\n",
    "        else:\n",
    "              continue\n",
    " \n",
    "    i = -1\n",
    "    \n",
    "    ##If entity 1 does not have an exact match\n",
    "    if match_1 != 1:\n",
    "        for t in doc:\n",
    "            i +=1\n",
    "            match = re.match(e1 , t)\n",
    "            if match:\n",
    "                print(f\"Exact match found of e1 with {t}\")\n",
    "                match_1 = 1\n",
    "                start_1 = i\n",
    "                end_1 = i+1\n",
    "                print(f'Span {start_1} to {end_1}')\n",
    "            else:\n",
    "                continue  \n",
    "  \n",
    "\n",
    "    i = -1\n",
    "    print(\" I RE-INITIALISED\")\n",
    "\n",
    "\n",
    "    #ENTITY 2\n",
    "    for t in doc:\n",
    "        i += 1\n",
    "        if t == e2 or t == e2_tok[0]:\n",
    "            if len(e2_tok) != 1:\n",
    "                print(f'Matched entity #2 is: {e2} ')\n",
    "                match_2 = 1\n",
    "                start_2 = i\n",
    "                end_2 = i + len(e2_tok)\n",
    "            else:\n",
    "                print(f'Matched entity #2 is: {e2} ')\n",
    "                match_2 = 1\n",
    "                start_2 = i\n",
    "                end_2 = i + 1\n",
    "        else:\n",
    "            continue\n",
    "  \n",
    "    i = -1\n",
    "  \n",
    "\n",
    "    ##If entity 2 does not have an exact match\n",
    "    if match_2 != 1:\n",
    "        for t in doc:\n",
    "            i +=1\n",
    "            match = re.match(e2 , t)\n",
    "            if match:\n",
    "                print(f\"Exact match found of e2 with {t}\")\n",
    "                match_2 = 1\n",
    "                start_2 = i\n",
    "                end_2 = i+1\n",
    "                print(f'Span {start_2} to {end_2}')\n",
    "            else:\n",
    "                continue      \n",
    "\n",
    "\n",
    "    e1_d = {}\n",
    "    e1_d['type'] = e1_type\n",
    "    e1_d['start'] = start_1\n",
    "    e1_d['end'] = end_1\n",
    "\n",
    "    e2_d = {}\n",
    "    e2_d['type'] = e2_type\n",
    "    e2_d['start'] = start_2\n",
    "    e2_d['end'] = end_2\n",
    "\n",
    "    entities = {}\n",
    "    entities[\"entities\"] = [e1_d, e2_d]\n",
    "\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_relations(label):\n",
    "    ## All the relations in ddi2013 are symmetric\n",
    "    rel = {}\n",
    "    rel[\"type\"] = label\n",
    "    rel[\"head\"] = 0 \n",
    "    rel[\"tail\"] = 1\n",
    "  \n",
    "    relation = {}\n",
    "    relation['relations'] = [rel]\n",
    "    \n",
    "    return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FOR TRAIN\n",
    "import csv\n",
    "import json\n",
    "\n",
    "cnt = 0\n",
    "entire_content = []\n",
    "##title = ['Unnamed: 0', 'index', 'sentence', 'entity-1', 'entity-1-type', 'entity-2', 'entity-2-type', 'label']\n",
    "\n",
    "with open('./train_train_added.tsv', newline='') as csvfile:\n",
    "    i = 0 \n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        final_row = {}\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        else : \n",
    "            i += 1\n",
    "    \n",
    "            ### Tokens in the dictionary\n",
    "            text = row[2]\n",
    "            text = tokenize_json(text)\n",
    "         \n",
    "            final_row['tokens'] = text\n",
    "         \n",
    "            ### Entities in the dictionary\n",
    "            entities = create_entities( row[2], row[3], row[4], row[5] , row[6], row[1])\n",
    "         \n",
    "            final_row['entities'] = entities[\"entities\"]\n",
    "         \n",
    "            relations = create_relations(row[7])\n",
    "         \n",
    "            final_row['relations'] = relations['relations']\n",
    "         \n",
    "            final_row['orig_id'] = row[1]\n",
    "        \n",
    "            entire_content.append(final_row)\n",
    "            cnt += 1\n",
    "            print(f'Have {cnt} relations till now')\n",
    "         \n",
    "        \n",
    "print(f'Have {cnt} total relations')\n",
    "\n",
    "with open('./train_ddi_json.json', 'w') as f:\n",
    "    json.dump(entire_content, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FOR TEST\n",
    "import csv\n",
    "import json\n",
    "\n",
    "cnt = 0\n",
    "entire_content = []\n",
    "##title = ['index', 'sentence', 'entity-1', 'entity-1-type', 'entity-2', 'entity-2-type', 'label']\n",
    "\n",
    "with open('./test_added.tsv', newline='') as csvfile:\n",
    "    i = 0 \n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        final_row = {}\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        else : \n",
    "            if row[0] == 'DDI-MedLine.d161.s5.p5':\n",
    "                continue\n",
    "            if row[0] == 'DDI-MedLine.d161.s6.p0':\n",
    "                continue  \n",
    "            if row[0] == 'DDI-MedLine.d161.s8.p2':\n",
    "                continue\n",
    "            i += 1\n",
    "    \n",
    "             ### Tokens in the dictionary\n",
    "            text = row[2]\n",
    "            text = tokenize_json(text)\n",
    "         \n",
    "            final_row['tokens'] = text\n",
    "         \n",
    "            ### Entities in the dictionary\n",
    "            entities = create_entities( row[2], row[3], row[4], row[5] , row[6], row[1])\n",
    "         \n",
    "            final_row['entities'] = entities[\"entities\"]\n",
    "         \n",
    "            relations = create_relations(row[7])\n",
    "         \n",
    "            final_row['relations'] = relations['relations']\n",
    "         \n",
    "            final_row['orig_id'] = row[1]\n",
    "        \n",
    "            entire_content.append(final_row)\n",
    "            cnt += 1\n",
    "            print(f'Have {cnt} relations till now')\n",
    "         \n",
    "        \n",
    "print(f'Have {cnt} total relations')\n",
    "\n",
    "with open('./test_ddi_json.json', 'w') as f:\n",
    "    json.dump(entire_content, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FOR TEST\n",
    "import csv\n",
    "import json\n",
    "\n",
    "cnt = 0\n",
    "entire_content = []\n",
    "##title = ['Unnamed: 0','index', 'sentence', 'entity-1', 'entity-1-type', 'entity-2', 'entity-2-type', 'label']\n",
    "\n",
    "with open('./train_dev_addeD.tsv', newline='') as csvfile:\n",
    "    i = 0 \n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        final_row = {}\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        else : \n",
    "            i += 1\n",
    "    \n",
    "             ### Tokens in the dictionary\n",
    "            text = row[2]\n",
    "            text = tokenize_json(text)\n",
    "         \n",
    "            final_row['tokens'] = text\n",
    "         \n",
    "            ### Entities in the dictionary\n",
    "            entities = create_entities( row[2], row[3], row[4], row[5] , row[6], row[1])\n",
    "         \n",
    "            final_row['entities'] = entities[\"entities\"]\n",
    "         \n",
    "            relations = create_relations(row[7])\n",
    "         \n",
    "            final_row['relations'] = relations['relations']\n",
    "         \n",
    "            final_row['orig_id'] = row[1]\n",
    "        \n",
    "            entire_content.append(final_row)\n",
    "            cnt += 1\n",
    "            print(f'Have {cnt} relations till now')\n",
    "         \n",
    "        \n",
    "print(f'Have {cnt} total relations')\n",
    "\n",
    "with open('./dev_ddi_json.json', 'w') as f:\n",
    "    json.dump(entire_content, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Craeting types.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elaborate_entity(entity):\n",
    "    e = {}\n",
    "    e['short'] = entity\n",
    "    e['verbose'] = entity\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elaborate_relation(relation):\n",
    "    r = {}\n",
    "    r['short'] = relation[4:]\n",
    "    r['verbose'] = relation\n",
    "    r['symmetric'] = True\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "entities = {}\n",
    "relations = {}\n",
    "\n",
    "entities_list = ['drug', 'group', 'brand', 'drug_n']\n",
    "for e in entities_list:\n",
    "    entities[e] = elaborate_entity(e)\n",
    "\n",
    "\n",
    "relations_list = ['DDI-mechanism', 'DDI-effect', 'DDI-advise', 'DDI-int']\n",
    "for r in relations_list:\n",
    "    relations[r] = elaborate_relation(r)\n",
    "\n",
    "types = {}\n",
    "types['entities'] = entities\n",
    "types['relations'] = relations\n",
    "\n",
    "with open('spert-master/DDI2013/ddi_types.json', 'w') as f:\n",
    "    json.dump(types, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
